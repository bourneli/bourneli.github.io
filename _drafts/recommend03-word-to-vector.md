---
layout: post
title: 推荐技术系列03：Word2Vector的原理和推荐中的应用
categories: [Recommendation,Word2Vector,NLP,Embedding]

---



## 技术背景

Word2Vector自从2013年被Google的Mikolov及其团队提出，目前被广泛的应用在工业界。虽然它是NLP领域的技术，但是也可以被用来解决物品推荐相关的问题。经实践证明，无论是直接使用Word2Vector做推荐，还是用于计算道具特征，均可以得到比较好的效果。本文主要介绍Word2Vector的原理，包括主要思路，优化tricks等；然后介绍工业界的相关应用案例。



## 工作原理

Word2Vector的主要作用是可以将语料中的所有单词（word）映射到一个固定维度的向量空间中，使得相近的词在这个空间中的距离较近。由于具有距离相似性，可以用来做聚类，分类，统计分析，可视化，所以word2vector属于一种预训练技术。它的做法是解决一个“假”的相邻词查找任务，在解决完这个任务的同时，得到所有的词向量。另一个类似的技术是Auto Encode，通过编码将原始数据压缩到一个低位的向量空间，然后通过解码将其还原为原始数据，但是最终只需要中间的向量。

这个“假”任务有两种形式:Skip-Gram和CBOW。这两个形式原理比较类似，但是Skip-Gram的形式更为简单，所以主要在Skip-Gram的形式下介绍相关原理和tricks。









## 应用案例



## 参考资料

