---
layout: post
title:  回顾近几年深度学习的发展
categories: [deep-learning]
---



今天看了[机器之心](https://www.jiqizhixin.com/)的一篇回顾文章：[告别2019：属于深度学习的十年，那些我们必须知道的经典](https://www.jiqizhixin.com/articles/2020-01-01)，笔者很有感触。10年之前，只有少数学术研究人员在深度学习领域默默耕耘，公共大多只知道它是机器学习领域中的一个分支。但是，随着计算机算力的高速发展，以及一些基于深度学习的杀手级应用出现（如图像识别，机器翻译），使得深度学习又被推到了聚光灯下。深度学习的核心运行机制虽然没有改变，但是围绕其发展的上层技术近10年层出不同，并且取得相当不错的效果，下面笔者简单的回顾相关的学术成果。



# 2011年：ReLU

在此之前，主流激活函数是sigmod，但是随着网络层次加深会出现梯度消失的现象，该技术有效的解决了梯度消失问题，目前ReLU已经被广泛的应用到深度学习实践中。



# 2012年：AlexNet

AlexNet在ImageNet挑战赛上取得成功，该方法吊打上一届的冠军和同届亚军，可以说是开启了这波人工智能浪潮的起点。从此之后，各种层数更多，效果更好的网络不断出现，使得一些基于图像应用能够被广泛的应用。这几年基于内容的应用如此火热（新闻推荐类应用，各大垂直社区，直播，小视频等），与此技术有千丝万缕的联系。



# 2013年：Word2Vector

毫不夸张的说，Word2Vector技术是深度自然语言处理的基石，在此之后几乎所有的基于深度学习的自然语言处理技术均是使用Word Embedding作为输入，如语言模型，QA系统，机器翻译，自动摘要等等。更难能可贵的是，除了在NLP领域以外，该技术还广泛的应用于物品推荐领域，自动学习物品的特征，提升下游物品推荐的效果。



# 2014年：GAN

GAN的核心逻辑是通过两个机器学习互相博弈的架构，使得模型可以通过以往的数据，生成一些新的数据，并且可以使得生成的数据和以往的数据非常类似，达到以假乱真的效果。比如在游戏领域，可以用GAN自动生成逼真的树，动物，山川等等，减少人力成本。在内容生产领域，可以根据文章内容和素材，使用GAN自动生成插图。



# 2015年：ResNet

ResNet和AlexNet类似，也是视觉识别中的杀手级突破，该网络在视觉识别问题上第一次超越了人类。其核心思想是通过在网络中添加一条捷径，使得网络传递中有价值的信息得到保留，该设计与LSTM中的细胞状态$C$有异曲同工之妙，不知道ResNet的作者们当时是否有借鉴。



# 2016年：AlphaGo

AlphaGo是计算机第一次完胜人类职业9段棋手，其背后的深度强化学习技术也被推上了风口浪尖。自从2016年后，深度强化学习技术确实火了几年，但是近几年又有回归理性的趋势。

笔者认为强化学习的环境模拟是一大障碍。游戏或者围棋这些问题的环境相对好创建，游戏的环境是现成的，围棋有棋谱。但是广告，商品推荐，feed流推荐应用中是将用户作为环境，用户的行为很难准确模拟，如果环境不准，那么在此之上的Agent学习出来的策略就会因为环境误差不断累积而不准。



# 2017年：Transformer

自从2014年Seq2Seq问世以来，该方法在机器翻译领域就吊打所有以前的方法。在此之后基于Seq2Seq的大多数改进基本上都可以归结为换着花样使用Attention。但是Transformer在这方面做到了极值，它用Attention完全替代了原来的LSTM，结果是在机器翻译问题上完胜之前的Seq2Seq架构，并且所需要的训练时间更短。



# 2018年：BERT

BERT的作用与Word2Vector类似，是一个预训练技术，用于计算词向量。但是BERT训练出来的embedding在不同语境下可以表现出不同的意义，在11项NLP任务中都取得了state of the art的效果。该方法也应用了Transformer的思想，可以是说是集大成之作。



简单总结上面的这些技术，除了ReLU是深度学习通用技术，其它的都集中在CV和NLP领域，而CV和NLP可以大量的应用于内容产业的多个环节，极大的提高生产效率，如内容创编，文章分发，低俗鉴别等等。最近几年内容行业的蓬勃发展，相关CV和NLP算法工程的年薪也水涨船高，也间接的证明了这点。正应验了邓小平的那句话：“科学技术是第一生产力”。

今天是2020年的第一天，是下个10年的开始，笔者非常期待下个十年AI领域有更多技术的突破，并且能够应用到工业界的不同细分产业。这样无论是我们AI从业人员，还是相关领域都是双赢的局面。

以上仅为作者自己的观点，如果有异议，欢迎与笔者进行探讨。





